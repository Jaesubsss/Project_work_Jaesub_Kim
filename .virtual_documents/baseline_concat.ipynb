!nvidia-smi


import pandas as pd
import numpy as np
import torch
import scripts
from functools import lru_cache
import torchmetrics
from torch import nn
import optuna


config = {"features" : {"fp_radius":2}, # chemical의 fingerprint 생성 radius를 2로 설정
          "optimizer": {"batch_size": 220, # 한번에 학습시킬 데이터의 양
                        "clip_norm":19, # 그라디언트 클리핑에 사용할 최대 norm 값
                        "learning_rate": 0.0004592646200179472, # 학습률
                        "stopping_patience":15}, # 개선되지 않는 epoch가 15번 이상 나오면 학습을 중단
          "model":{"embed_dim":485, # input을 embedding할 때 사용할 차원
                 "hidden_dim":696, # hidden layer의 차원
                 "dropout":0.48541242824674574, # 40퍼센트의 노드를 랜덤하게 드랍아웃 
                 "n_layers": 4, # 3개의 hidden layer를 사용
                 "norm": "batchnorm"}, # batch normalization을 사용하여 모델이 학습 중 출력 분포를 정규화하여 학습을 안정화
         "env": {"fold": 0, # 0번째 fold를 사용하여 학습. 이는 음 n_fold에 들어갈 값을 의미하는 듯 하다. 
                "device":"cuda:2", # GPU자원을 사용할 장치를 지정한다. 
                 "max_epochs": 100, # 최대 epoch 수 
                 "search_hyperparameters":False}} # hyper parameter 이미 있으니 안쓴다.


# concatenated
concat_train_dataset, concat_validation_dataset, concat_test_dataset = scripts.get_data(n_fold = config["env"]["fold"],
                                                           fp_radius = config["features"]["fp_radius"],typ = "concat")


# concatenated model
_, concat_model = scripts.train_model(config, torch.utils.data.ConcatDataset([concat_train_dataset, concat_validation_dataset]), None, use_momentum=False)
device = torch.device(config["env"]["device"])
metrics = torchmetrics.MetricTracker(torchmetrics.MetricCollection(
    {"R_cellwise_residuals":scripts.GroupwiseMetric(metric=torchmetrics.functional.pearson_corrcoef,
                          grouping="drugs",
                          average="macro",
                          residualize=True),
    "R_cellwise":scripts.GroupwiseMetric(metric=torchmetrics.functional.pearson_corrcoef,
                          grouping="cell_lines",
                          average="macro",
                          residualize=False),
    "MSE":torchmetrics.MeanSquaredError()}))
metrics.to(device)
concat_test_dataloader = torch.utils.data.DataLoader(concat_test_dataset,
                                       batch_size=config["optimizer"]["batch_size"],
                                       drop_last=False,
                                      shuffle=False,
                                      pin_memory=True)


concat_final_metrics = scripts.evaluate_step(concat_model, concat_test_dataloader, metrics, device, save_predictions = True, model_name = "baseline", dataset_name = "concatenated")
print(f"All 4 concatenated model: {concat_final_metrics}")


from datetime import datetime

result = concat_final_metrics

model_name = "baseline_concat"
result["Model"] = model_name
time = datetime.now().strftime("%Y%m%d_%H:%M")
result["Time"] = time

result_df = pd.DataFrame([result])


new_column_order = ["Model", "MSE", "R_cellwise", "R_cellwise_residuals","Time"]
result_df = result_df[new_column_order]

ev_table = pd.read_csv("results/evalutation_table.csv")
ev_table = pd.concat([ev_table, result_df], ignore_index=True)
ev_table = ev_table.drop_duplicates(subset=["Model"])
display(ev_table)


ev_table.to_csv("results/evalutation_table.csv", index = False)



